{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18682d20",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2.2em; font-weight:bold; text-align:center;\">Exploratory Data Analysis</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e8bbc",
   "metadata": {},
   "source": [
    "This project serves as a **Proof of Concept (PoC)** for identifying potential financial crime within corporate banking transactions. \n",
    "\n",
    "The data covers the period from **April 2, 2025** to **December 31, 2025**, based on the assumption that in mid-2025, trade tensions lead to increased abnormal or suspicious transaction activities.\n",
    "\n",
    "For exploratory data analysis (EDA), we will:\n",
    "\n",
    "- Integrate dynamic currency conversion using the Riksbanken API\n",
    "\n",
    "- Explore missing values\n",
    "\n",
    "- Perform univariate and bivariate analysis: Identify potential features related to fraud\n",
    "\n",
    "- Conduct descriptive analytics using SQL\n",
    "\n",
    "- Analyze data distribution and identify outliers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acec71c",
   "metadata": {},
   "source": [
    "## <h2 style=\"font-size: 1.6em; font-weight: bold;\"> 1. Data Collection </h2>\n",
    "Import Required Packages and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c86a414",
   "metadata": {},
   "source": [
    "**Importing Pandas, Numpy, Matplotlib, Seaborn, Plotly.express and Warings Library.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25c60aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d250d",
   "metadata": {},
   "source": [
    "**Import the CSV Data as Pandas DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e36366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data from 2 reports and merge them using a left join on `from_account_id`\n",
    "\n",
    "transaction_df = pd.read_csv('data/transactions.csv')\n",
    "customer_df = pd.read_csv('data/customers.csv')\n",
    "sum_statistic_df = pd.read_csv('data/summary statistics.csv')\n",
    "\n",
    "df = transaction_df.merge(customer_df, on='customer_id', how='left') \\\n",
    "                   .merge(sum_statistic_df, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f23496",
   "metadata": {},
   "source": [
    "Handle duplicate columns after merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c69fbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with identical values:\n",
      "currency_x and currency_y\n",
      "currency_x and currency\n",
      "amount and amount_f\n",
      "country_x and country_y\n",
      "currency_y and currency\n",
      "available_balance_x and booked_balance\n",
      "available_balance_x and available_balance_y\n",
      "booked_balance and available_balance_y\n",
      "credit_limit_x and credit_limit_y\n",
      "Dropped columns: ['available_balance_y', 'currency', 'country_y', 'credit_limit_y', 'amount_f', 'currency_y', 'booked_balance']\n",
      "Remaining columns: ['available_balance_x', 'credit_limit_x', 'country_x', 'currency_x', 'amount']\n"
     ]
    }
   ],
   "source": [
    "dup_cols = []\n",
    "cols = df.columns.tolist()\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        if df[cols[i]].equals(df[cols[j]]):\n",
    "            dup_cols.append((cols[i], cols[j]))\n",
    "print(\"Columns with identical values:\")\n",
    "for c1, c2 in dup_cols:\n",
    "    print(f\"{c1} and {c2}\")\n",
    "    \n",
    "dropped = set()\n",
    "kept = set()\n",
    "\n",
    "for c1, c2 in dup_cols:\n",
    "    if c2 not in dropped:\n",
    "        df.drop(columns=c2, inplace=True)\n",
    "        dropped.add(c2)\n",
    "        kept.add(c1)     \n",
    "print(\"Dropped columns:\", list(dropped))\n",
    "print (\"Remaining columns:\", list(kept) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7cf355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'available_balance_x': 'available_balance',\n",
    "    'country_x' : 'country',\n",
    "    'currency_x': 'currency',\n",
    "    'credit_limit_x' : 'credit_limit'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33db344",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/RAW_transaction_monitoring_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a6456",
   "metadata": {},
   "source": [
    "**Dataset Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc5a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10716 entries, 0 to 10715\n",
      "Data columns (total 35 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   customer_id                      10716 non-null  object \n",
      " 1   transaction_id                   10716 non-null  object \n",
      " 2   currency                         10716 non-null  object \n",
      " 3   booking_date                     10716 non-null  object \n",
      " 4   value_date                       10716 non-null  object \n",
      " 5   transaction_date                 10716 non-null  object \n",
      " 6   payment_date                     10716 non-null  object \n",
      " 7   type_description                 10716 non-null  object \n",
      " 8   narrative                        10716 non-null  object \n",
      " 9   status_x                         10716 non-null  object \n",
      " 10  counterparty_name                10716 non-null  object \n",
      " 11  amount                           10716 non-null  float64\n",
      " 12  card_number                      2126 non-null   object \n",
      " 13  message                          2110 non-null   object \n",
      " 14  own_message                      2110 non-null   object \n",
      " 15  country                          10716 non-null  object \n",
      " 16  account_numbers                  10716 non-null  object \n",
      " 17  account_name                     10716 non-null  object \n",
      " 18  product                          10716 non-null  object \n",
      " 19  account_type                     10716 non-null  object \n",
      " 20  available_balance                10716 non-null  float64\n",
      " 21  value_dated_balance              10716 non-null  float64\n",
      " 22  status_y                         10716 non-null  object \n",
      " 23  credit_limit                     10716 non-null  float64\n",
      " 24  latest_transaction_booking_date  10716 non-null  object \n",
      " 25  registration_number              10716 non-null  object \n",
      " 26  bank.name                        10716 non-null  object \n",
      " 27  bank.bic                         10716 non-null  object \n",
      " 28  bank.country                     10716 non-null  object \n",
      " 29  total_volume                     10716 non-null  float64\n",
      " 30  avg_amount                       10716 non-null  float64\n",
      " 31  max_amount                       10716 non-null  float64\n",
      " 32  min_amount                       10716 non-null  float64\n",
      " 33  transaction_count                10716 non-null  int64  \n",
      " 34  last_transaction_date            10716 non-null  object \n",
      "dtypes: float64(8), int64(1), object(26)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29fac9",
   "metadata": {},
   "source": [
    "We have a dataset with 10,716 records and 35 columns:\n",
    "\n",
    "  - Categorical features: 26\n",
    "\n",
    "  - Numeric features: 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce039c45",
   "metadata": {},
   "source": [
    "## <h2 style=\"font-size: 1.6em; font-weight: bold;\"> 2. Data Wrangling </h2>\n",
    "\n",
    "- Removed Duplicate Entries\n",
    "\n",
    "- Converted amounts to EUR using exchange rates from the Riskbanken open API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "653857b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d523055",
   "metadata": {},
   "source": [
    "The data has 200 duplicate records. Drop all duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "109813d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove Duplicate\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e2c06",
   "metadata": {},
   "source": [
    "Converted amounts to EUR to standardize all currencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cabf5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching rate for DKK: HTTP Error 429: Too Many Requests\n",
      "Error fetching rate for NOK: HTTP Error 429: Too Many Requests\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>currency</th>\n",
       "      <th>amount_eur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.31</td>\n",
       "      <td>DKK</td>\n",
       "      <td>16.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1195.89</td>\n",
       "      <td>NOK</td>\n",
       "      <td>1195.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5339.23</td>\n",
       "      <td>EUR</td>\n",
       "      <td>5339.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>845.71</td>\n",
       "      <td>EUR</td>\n",
       "      <td>845.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4808.88</td>\n",
       "      <td>NOK</td>\n",
       "      <td>4808.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10604</th>\n",
       "      <td>2013.87</td>\n",
       "      <td>SEK</td>\n",
       "      <td>183.957068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10605</th>\n",
       "      <td>11144.82</td>\n",
       "      <td>SEK</td>\n",
       "      <td>1018.024206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10606</th>\n",
       "      <td>152.18</td>\n",
       "      <td>EUR</td>\n",
       "      <td>152.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10607</th>\n",
       "      <td>2832.87</td>\n",
       "      <td>DKK</td>\n",
       "      <td>2832.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10608</th>\n",
       "      <td>15114.84</td>\n",
       "      <td>EUR</td>\n",
       "      <td>15114.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10609 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         amount currency    amount_eur\n",
       "0         16.31      DKK     16.310000\n",
       "1       1195.89      NOK   1195.890000\n",
       "2       5339.23      EUR   5339.230000\n",
       "3        845.71      EUR    845.710000\n",
       "4       4808.88      NOK   4808.880000\n",
       "...         ...      ...           ...\n",
       "10604   2013.87      SEK    183.957068\n",
       "10605  11144.82      SEK   1018.024206\n",
       "10606    152.18      EUR    152.180000\n",
       "10607   2832.87      DKK   2832.870000\n",
       "10608  15114.84      EUR  15114.840000\n",
       "\n",
       "[10609 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import urllib.request, json\n",
    "\n",
    "# Set up date\n",
    "single_date = datetime.today() - timedelta(days=5)\n",
    "date_str = single_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Ensure all currency codes are uppercase\n",
    "currencies = df['currency'].unique()\n",
    "\n",
    "# Build currency-to-series map\n",
    "currency_to_series = {\n",
    "    cur: f'SEK{cur}PMI' if cur != 'SEK' else 'SEK'\n",
    "    for cur in currencies\n",
    "}\n",
    "\n",
    "rate_dict = {}\n",
    "\n",
    "# Loop to fetch exchange rates\n",
    "for cur in currencies:\n",
    "    if cur == 'EUR':\n",
    "        rate_dict[cur] = 1.0  # EUR to EUR\n",
    "        continue\n",
    "    if cur == 'SEK':\n",
    "        series1 = 'SEK'\n",
    "    else:\n",
    "        series1 = currency_to_series[cur]\n",
    "\n",
    "    series1 = currency_to_series[cur]\n",
    "    url = f'https://api.riksbank.se/swea/v1/CrossRates/{series1}/SEKEURPMI/{date_str}/{date_str}'\n",
    "\n",
    "    try:\n",
    "        req = urllib.request.Request(url)\n",
    "        req.get_method = lambda: 'GET'\n",
    "        response = urllib.request.urlopen(req)\n",
    "        content = response.read()\n",
    "        data = json.loads(content)\n",
    "\n",
    "        # Handle different JSON structures\n",
    "        if isinstance(data, list) and data:\n",
    "            rate = data[0]['value']\n",
    "            rate_dict[cur] = float(rate)\n",
    "        elif isinstance(data, dict) and 'value' in data:\n",
    "            rate_dict[cur] = float(data['value'])\n",
    "        else:\n",
    "            rate_dict[cur] = 1.0\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching rate for {cur}: {e}\")\n",
    "        rate_dict[cur] = 1.0\n",
    "\n",
    "# Apply conversion to EUR\n",
    "df['amount_eur'] = df.apply(\n",
    "    lambda x: float(x['amount']) if x['currency'].upper() == 'EUR'\n",
    "    else (\n",
    "        float(x['amount']) / rate_dict.get('SEK', 1.0) if x['currency'].upper() == 'SEK'\n",
    "        else float(x['amount']) * rate_dict.get(x['currency'].upper(), 1.0)\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df[['amount', 'currency','amount_eur']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec11d2",
   "metadata": {},
   "source": [
    "## <h2 style=\"font-size: 1.6em; font-weight: bold;\"> 3. EDA </h2>\n",
    "\n",
    "- Explored missing values.\n",
    "\n",
    "- Performed univariate and bivariate analysis.\n",
    "\n",
    "- Performed descriptive analytics using SQL.\n",
    "\n",
    "- Analyzed data distribution and identified outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e22d906",
   "metadata": {},
   "source": [
    "**3.1 Missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "907c76ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_number    80.17\n",
       "message        80.35\n",
       "own_message    80.35\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_pct = round(df.isnull().sum()*100/len(df),2)\n",
    "missing_column_pct = missing_pct[missing_pct> 1]\n",
    "missing_column_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeee2e7",
   "metadata": {},
   "source": [
    "Let’s examine the relationship between missing values in the columns and the target variable `is_fraud` determine the best way to handle them during Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42e06502",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: is_fraud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m df_copy \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      5\u001b[0m df_copy[col\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_na\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(df_copy[col]\u001b[38;5;241m.\u001b[39misnull(), \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m miss \u001b[38;5;241m=\u001b[39m \u001b[43mdf_copy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_na\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_fraud\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, i)\n\u001b[0;32m      9\u001b[0m sns\u001b[38;5;241m.\u001b[39mbarplot(data\u001b[38;5;241m=\u001b[39mmiss, x\u001b[38;5;241m=\u001b[39mcol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_na\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_fraud\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdarkblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\linhh\\OneDrive\\Desktop\\Linh\\Project\\Financial-Crime-Detection-During-Trade-Wars-2025\\venv\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:1771\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1765\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1768\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1769\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1770\u001b[0m     )\n\u001b[1;32m-> 1771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\linhh\\OneDrive\\Desktop\\Linh\\Project\\Financial-Crime-Detection-During-Trade-Wars-2025\\venv\\lib\\site-packages\\pandas\\core\\base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: is_fraud'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 10))\n",
    "\n",
    "for i, col in enumerate(missing_column_pct.index, 1):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[col+'_na'] = np.where(df_copy[col].isnull(), 1, 0)\n",
    "    \n",
    "    miss = df_copy.groupby(col+'_na')['is_fraud'].mean().reset_index()\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.barplot(data=miss, x=col+'_na', y='is_fraud', color='darkblue')\n",
    "    plt.title(f'{col}')\n",
    "    plt.xlabel('Missing (0 = No, 1 = Yes)')\n",
    "    plt.ylabel('Mean is_fraud')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7f878",
   "metadata": {},
   "source": [
    "So, only `related_trade_invoice_id` shows a relationship with is_fraud; the others can be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2881753",
   "metadata": {},
   "source": [
    "**3.2 Univariate and Bivariate analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1770c0",
   "metadata": {},
   "source": [
    "**Numeric Features (Continuous Variable)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049628a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feature = df.select_dtypes (include='number')\n",
    "numerical_feature.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see, most of the numeric features are continuous variables. Let’s explore them further.\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, col in enumerate(numerical_feature,1):\n",
    "      df_copy = df.copy()\n",
    "      plt.subplot(2, 2, i)\n",
    "      sns.histplot(df_copy[col], bins=50, kde=True, color='darkblue')\n",
    "      plt.title(f'Distribution of {col}')\n",
    "      plt.xlabel(col)\n",
    "      plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec51a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_counts = (100.00* df['is_fraud'].value_counts()/ len(df)).sort_index()\n",
    "fraud_df = fraud_counts.reset_index()\n",
    "fraud_df.columns = ['is_fraud','pct']\n",
    "\n",
    "plt.figure (figsize=(6,8))\n",
    "ax = sns.barplot(fraud_df, x='is_fraud', y='pct',color='lightcoral', edgecolor='black')\n",
    "\n",
    "for index,row in fraud_df.iterrows():\n",
    "    ax.text (x=index, y=row['pct'] + 0.9, s=f\"{row['pct']:.2f}%\", ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587e6c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feature.corr()['is_fraud'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07619297",
   "metadata": {},
   "source": [
    "`amount_eur` showed the highest correlation with the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4012474a",
   "metadata": {},
   "source": [
    "**Temporal Variables (Ex: Datetime Variables)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7beb8",
   "metadata": {},
   "source": [
    "Convert  `transaction_date`, `booking_date`, `value_date`, and `payment_date` from object type to datetime format, then transform them into numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8bbae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transaction_day'] = pd.to_datetime(df['transaction_date']).dt.day\n",
    "df['transaction_day_of_week'] = pd.to_datetime(df['transaction_date']).dt.day_of_week\n",
    "df['transaction_month'] = pd.to_datetime(df['transaction_date']).dt.month\n",
    "\n",
    "\n",
    "df['booking_day'] = pd.to_datetime(df['booking_date']).dt.day\n",
    "df['booking_day_of_week'] = pd.to_datetime(df['booking_day']).dt.day_of_week\n",
    "df['booking_month'] = pd.to_datetime(df['booking_date']).dt.month\n",
    "\n",
    "\n",
    "df['value_day'] = pd.to_datetime(df['value_date']).dt.day\n",
    "df['value_day_of_week'] = pd.to_datetime(df['value_day']).dt.day_of_week\n",
    "df['value_month'] = pd.to_datetime(df['value_date']).dt.month\n",
    "\n",
    "\n",
    "df['payment_day'] = pd.to_datetime(df['payment_date']).dt.day\n",
    "df['payment_day_of_week'] = pd.to_datetime(df['payment_day']).dt.day_of_week\n",
    "df['payment_month'] = pd.to_datetime(df['payment_date']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8ecbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_month = df.groupby(df['transaction_month'])['is_fraud'].mean().reset_index()\n",
    "sns.lineplot(transaction_month, x='transaction_month', y='is_fraud', marker='o', color='darkblue')\n",
    "plt.title('Fraud Rate by Transaction Month')\n",
    "plt.xlabel('Transaction Month')\n",
    "plt.ylabel('Fraud Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transaction_month'].corr(df['is_fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7cfb9a",
   "metadata": {},
   "source": [
    "`transaction_mon` shows a positive Pearson correlation coefficient with `is_fraud`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9bb746",
   "metadata": {},
   "source": [
    "**Insight:**\n",
    "\n",
    "- Fraud rates vary, ranging from about 2.16% to 4.19%.\n",
    "\n",
    "- August and November show nearly double the fraud rate compared to June.\n",
    "\n",
    "- The peak in August could be related to increased trade tensions following the expiration of the tariff pause\n",
    "\n",
    "- Fraud rates hover around 2.5%-3.1%, indicating steady but moderate risk.\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- Investigate why months 8 and 11 see spikes in fraud.\n",
    "\n",
    "- Increase fraud monitoring and controls during high-fraud months.\n",
    "\n",
    "- Incorporate transaction month as a feature in fraud prediction models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c95fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Value_month = df.groupby(df['value_month'])['is_fraud'].mean().reset_index()\n",
    "sns.lineplot(Value_month, x='value_month', y='is_fraud', marker='o', color='darkblue')\n",
    "plt.title('Fraud Rate by Value Month')\n",
    "plt.xlabel('Value Month')\n",
    "plt.ylabel('Fraud Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6205e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value_month'].corr(df['is_fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15fa12",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "\n",
    "- Fraud rates begin to rise starting in April, possibly linked to the beginning of trade tensions.\n",
    "\n",
    "- Peaks occur in August (3.97%) and November (4.02%), aligning with patterns observed in `transaction_month`.\n",
    "\n",
    "**Recommendations**\n",
    "\n",
    "- Strengthen fraud detection efforts in August and November, consistent with observed peaks.\n",
    "\n",
    "- Investigate factors contributing to the increase in fraud beginning in April.\n",
    "\n",
    "- Integrate both `transaction_mon` and `value_mon` features into predictive models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1007acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s analyze the relationship between is_fraud and the other temporal features.\n",
    "temporal_features = df[[feature for feature in df.columns if 'mon' in feature] + ['is_fraud']]\n",
    "tem_corr = temporal_features.corr()['is_fraud']\n",
    "tem_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ef682",
   "metadata": {},
   "source": [
    "**Categorical Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00544360",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = df.select_dtypes(include='object')\n",
    "categorical_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc581a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the number of unique categories in each categorical (object) column.\n",
    "for feature in categorical_features: \n",
    "    count_value = categorical_features[feature].value_counts()\n",
    "    print (feature,'-', len(count_value),'categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db160434",
   "metadata": {},
   "source": [
    "**3.3 Descriptive analytics using SQL**\n",
    "\n",
    "**Purpose:** From a business perspective, define insights: \"what the data tells us?\". Broken down into two components:\n",
    "\n",
    "- Overview of Key Metrics: \n",
    "\n",
    "        What are the lowest and highest amounts of fraudulent transactions?\n",
    "\n",
    "        How many fraud vs. non-fraud transactions and their percentage?\n",
    "       \n",
    "\n",
    "- Transaction Trends and Behavior:\n",
    "\n",
    "       How many transactions were sent inside vs. outside the Nordic region?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688da3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython-sql\n",
    "import sqlite3\n",
    "\n",
    "# Connect to created in-memory database\n",
    "con = sqlite3.connect(':memory:')\n",
    "df.to_sql ('RAW_nordic_transactions_with_fraud', con, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c4e42",
   "metadata": {},
   "source": [
    "*What are the lowest and highest amounts of fraudulent transactions?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "Select 'lowest_transaction' as category, from_account_name, counterparty_country,currency, amount_eur, is_fraud \n",
    "From \n",
    "(Select *\n",
    "From RAW_nordic_transactions_with_fraud\n",
    "Where is_fraud = '1'\n",
    "Order by amount_eur asc\n",
    "Limit 1)\n",
    "\n",
    "UNION ALL\n",
    "Select 'highest_transaction' as category, from_account_name, counterparty_country,currency, amount_eur, is_fraud \n",
    "From \n",
    "(Select *\n",
    "From RAW_nordic_transactions_with_fraud\n",
    "Where is_fraud = '1'\n",
    "Order by amount_eur desc\n",
    "Limit 1)\n",
    "\n",
    "'''\n",
    "\n",
    "df_result = pd.read_sql_query(query, con)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d45636",
   "metadata": {},
   "source": [
    "**Insight:**\n",
    "\n",
    "- Fraudulent amounts span from low (small test transfers) to high (attempts to extract large sums).\n",
    "- Both the lowest and highest transaction amounts were sent to high-risk countries, based on sanctions and the 2025 trade tension tariff threats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd92bf0e",
   "metadata": {},
   "source": [
    "*How many fraud vs. non-fraud transactions and their percentage?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "Select \n",
    "is_fraud, count (*) as transaction_count,\n",
    "Round (100.00 * COUNT(*) / 10116,2) as percentage\n",
    "From RAW_nordic_transactions_with_fraud\n",
    "Group by is_fraud\n",
    "'''\n",
    "\n",
    "df_result = pd.read_sql_query (query, con)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4500e6c6",
   "metadata": {},
   "source": [
    "**Insight:**   \n",
    "\n",
    "- Fraud is likely a small percentage (2.97%) compared to 97.03% of non-fraudulent transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e821445",
   "metadata": {},
   "source": [
    "*How many transactions were sent inside vs. outside the Nordic region?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "Select region, count (*) as transaction_count, \n",
    "Round (100* count (*)/ 10116, 2) as percentage\n",
    "From \n",
    "(Select *,\n",
    "Case when counterparty_country IN ('SE', 'NO', 'FI', 'DK', 'IS') Then 'Nordic' else 'non_Nordic' End as region\n",
    "From RAW_nordic_transactions_with_fraud\n",
    ")\n",
    "Group by region\n",
    "'''\n",
    "df_result = pd.read_sql_query (query, con)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9948900",
   "metadata": {},
   "source": [
    "**Insight:**  \n",
    "\n",
    "- Transactions are nearly evenly split: 47% from Nordic, 53% from non-Nordic.\n",
    "\n",
    "- There are slightly more transactions coming from non-Nordic regions than Nordic ones.\n",
    "\n",
    "**Suggestion:** \n",
    "\n",
    "- Segment fraud prevention strategies by region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46648c09",
   "metadata": {},
   "source": [
    "**3.4 Outliers and Data Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093fa53",
   "metadata": {},
   "source": [
    "As we discovered, most numeric features are skewed. Therefore, we will apply a log transformation to better identify outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d56ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, col in enumerate(numerical_feature,1):\n",
    "    df_copy=df.copy()\n",
    "    if 0 in df_copy[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        plt.subplot(2, 2, i)\n",
    "        df_copy[col] = np.log(df_copy[col])\n",
    "        sns.boxplot(df_copy, y=col)\n",
    "        plt.title(f'{col}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e6d35",
   "metadata": {},
   "source": [
    "As we observed, most of the numeric features contain outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929db0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/EDA_nordic_transactions_with_fraud.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
